<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Marco Conati</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="content"> 
							<div class="inner">
								<h1>Marco Conati</h1>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">About me</a></li>
								<li><a href="#work">Projects</a></li>
								<!-- <li><a href="#about">Notes</a></li> -->
								<li><a href="#contact">Contact</a></li>
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major">About me</h2>
								<span class="image main"><img src="images/pic01.jpg" alt="" /></span>
								<p>Hello! I'm Marco, a current MS Robotics student at the University of Michigan. My previous exploits include a BS Engineering from Harvey Mudd and 1 year stint as a Systems Engineer at Trellisware Technologies. I'm interested in AI and controls, hoping to contribute to the development of human-centered AI or intelligent robots. For a quick look into my background, check out my <a href = #resume>resume!</a> Or, for a much more thorough look at my technical work over the years, check out my <a href="#work">projects</a>.</p>
								<p>On a less academic note, I'm a big fan of swimming, cooking, cats and riddles. Feel free to send me a <a href="#contact">message!</a></p>
								<p><b>Ready for a swim at NCAAs 2022:</b></p>
								<span class="image main"><img src="images/03.jpg" loading='lazy'  alt="" /></span>
								<p><b>Cooking with close ones:</b></p>
								<span class="image main"><img src="images/02.jpg" loading='lazy' alt="" /></span>
								<p><b>Family cats! Max on the left and Leo on the right:</b></p>
								<span class="image main"><img src="images/01.jpg" loading='lazy' alt="" /></span>
							</article>

						<!-- Work -->
							<article id="work">
								<h2 class="major">Projects</h2>
								<span class="image main"><img src="images/pic02.jpg" loading='lazy' alt="" /></span>
								<p>Here is a running list of my completed projects, ranging from silly programs to research at HMC/UMich and personal projects. For an example of code I built and managed solo, I recommend checking out <a href = "#Chopin">Style Transfer with Transformers</a>. This is from my senior year undergrad (2 years ago), but my more recent research is not public (yet) and more recent projects (like ARMLAB), were done in a group. Each item links to a small project summary page, and <b>bolded</b> projects are ones I'm most proud of:

									<h4>Classical Robotics/Controls</h4>
									<li><a href = "#ROAHM"><b>ROAHM research - Improving Dynamic Behavior of RTD-Based Manipulation (current)</b></a></li>
									<li><a href = "#ARMLAB"><b>ARMLAB - Programming a Robotic Manipulator for Basic Tasks</b></a></li>
									<li><a href = "#BOTLAB">BOTLAB - Making a Mini Forklift with the UMich MBot Platform (current)</a></li>
									<li><a href = "#BRG">BRG research- 3D Additive Printing with Control (current)</a></li>
									<li><a href = "#BlimpKF"><b>Extended Kalman Filter Blimp tracking</b></a></li>
									<li><a href = "#Syntiant">Door Security System - Syntiant Clinic</a></li>
									<li><a href = "#Drone"> <b>Particle Filter Localization of a simple robot</b></a></li>
									<li><a href = "#Pendulum">State Space Inverted Pendulum Simulation in Simulink</a></li>
									<li><a href = "#e80">PID-based Aquatic Robot</a></li>
									<li><a href = "#Millennium">Spatial Navigation - Millennium Clinic</a></li>


									<p></p>
									<h4>Deep Learning/NLP</h4>
									<li><a href = "#Chopin"><b>Style Transfer with Transformers (HMC MIR research)</b></a></li>
									<li><a href = "#LRP"><b>Low-Resource Pretraining with Jukebox (HMC MIR research)</b></a></li>
									<li><a href = "#LSTM"><b>LSTM Seq to Seq model for Translation</b></a></li>
									<li><a href = "#CALM">Codified Audio Language Modeling for Instrument Detection</a></li>
									<li><a href = "#CNN">CNNs and Autoencoders</a></li>
									<li><a href = "#RNN">RNN for Language Classification</a></li>
									<li><a href = "#TsaiDL">Numpy Neural Net</a></li>
									<li><a href = "#Torch">Making a Pytorch Rundown</a></li>
								
									<p></p>
									<h4>Reinforcement Learning</h4>
									<li><a href = "#Alphazero"><b>Recreating Alphazero</b></a></li>
									<li><a href = "#DS">RL with David Silver</a></li>
									

									<p></p>
									<h4>Signal Processing</h4>
									<li><a href = "#AnalogDigitalFilter"><b>Building Analog and Digital Filters</b></a></li>
									<li><a href = "#MusicTrack">Tracking a Musical Performance in Realtime</a></li>
									<li><a href = "#e190">Implementing the Shazam paper for Music Recognition</a></li>
									
									
						
									<p></p>
									<h4>Programming</h4>

									<li><a href = "#A">Using A* search to design a city</a></li>
									<li><a href = "#searches">Implementing and speed testing some array search algorithms</a></li>
									<li><a href = "#rats">Solving a riddle with Dynamic Programming</a></li>
									<li><a href = "#hashTree">Datastructures @HMC: Trees, HashTables, and More!</a></li>
								
								<br></br>
								<p><i>Also, about half of the projects pages have tangentially-related AI generated art in them, which I find pretty fun</i></p>
							</article>

						<!-- About -->
							<!-- <article id="about">
								<h2 class="major">Notes</h2>
								<span class="image main"><img src="images/pic03.jpg" loading='lazy' alt="" /></span>
								<p>As an ongoing project, I have been transferring and reviewing my favorite notes from (and since) Mudd into digital format. I have built the basic framework for this site, so you can see what I have learned about, but it is currently only about 25% populated. I'm currently populating about 3 pages per week, so it should be done in mid-late 2023; right now, controls and reinforcement learning are the most populated. Also, brace your eyes, the html quality is dire. <a href="./website.html">Here it is!</a></p>
							</article> -->
						
						<!-- Projects -->
						<article id="Chopin">
							<h2 class="major">Chopin Style Transfer</h2>
							<span class="image main"><img src="images/Chopin.jpg" loading='lazy' alt="" /></span>
							<p>My code for this project is <a href = 'https://github.com/mconati/ChopinStyle/tree/main/MDEModels'>here.</a> This was my second project working with Prof Tsai in the MIR lab. 
								<p> This project aimed to generate Chopin-esque piano scores. In my literature review, I found that state-of-the-art score
								generation models struggled to emulate the long-term structure and style of human-composed
								pieces, resulting in forgotten motifs, over-repetition, jarring jumps, sparse sections, and
								distasteful chords. To maintain structure, we constrained our generative process, building our
								score from a database of left- and right-hand Chopin measures. At a high level, our approach
								started with the right-hand part from a random Chopin piece, built a left-hand score from the
								database of left-hand measures, and then repeated the process to replace the original right-hand.
								As we were using Chopin's measures directly, musical style would be maintained, and the
								structure of the original right-hand should persist through generation. I compiled the left/right
								hand measure database, created a BERT model with a custom encoder for note events, and
								trained two such BERT models to predict right/left hand compatibility and next measure
								prediction, respectively. My custom transformer embedding treated each measure as sequence of
								note events, each defined by the hand configuration along with the octave and pitch of the lowest
								note. This project was put on hold as I graduated in the Spring, but it is being resumed this Fall
								by a new group of students. Future work will use the two transformers in concert to generate new
								scores based on continuity between measures (next measure prediction) and compatibility
								between hands.</p></p>
						</article>
							<article id="LRP">
								<h2 class="major">Low-Resource Pretraining</h2>
								<span class="image main"><img src="images/jukebox.png" loading='lazy' alt="" /></span>
								<p>My code for this project is <a href = 'https://github.com/HMC-MIR/LowSourcePretraining/tree/main/Jukebox/jukebox'>here.</a>
								This was my first main project in the HMC MIR lab. It involved building upon the work of Stanford's Liang et al. in their Codified Audio
								Language Modeling paper. I also build upon my previous experience with Liang et al.'s code from my <a href = "#CALM">instrument detection project</a>. They had demonstrated that audio features extracted from the middle
								layer of OpenAI's music generation model, Jukebox, contained rich information for downstream
								MIR tasks. We sought to improve feature extraction by finetuning the output layers of a Jukebox
								model for benchmark MIR datasets. To this end, I created a modified Jukebox-style model with a
								flexible number of unfrozen layers and MIR-specific training objective in Pytorch. I successfully
								implemented the modified model, but the additional finetuning had no significant effect on our
								targeted benchmarks.</p>
							</article>
							<article id="CALM">
								<h2 class="major">Instrument Detection</h2>
								<span class="image main"><img src="images/octopus.png" loading='lazy' alt="" /></span>
								<p>Building upon the work of Stanford's Liang et. al, I worked with Alec Vercruysse to demonstrate that codified audio language modeling can learn useful representations for instrument identification. To this end, we used representations from layers within Jukebox: a generative model for music. Jukebox representations are used as input features to train shallow probes; each probe is trained to identify the presence of a specific instrument. As input data, the OpenMIC-2018 dataset was used. This dataset contains 10 second excerpts of audio that are partially labeled for the presence or absence of 20 instrument classes. Our results indicated that our probes were unable to match state-of-the-art performance. Further investigation also revealed that while some of the best performing models were achieved with few to no hidden layers, the probes still learn a complicated representation of Jukebox output features.</p>
								<p>Our full report is <a href="https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/CALM.pdf">here</a> and code is<a href = 'https://github.com/mconati/E208'> here </a></p>
								Embedded report:
								<iframe src="https://drive.google.com/file/d/1BrcJW-Lda-B1bNtUYVFKy2UVgKqppKd2/preview" loading='lazy' width="100%" height="600" allow="autoplay"></iframe>
							</article>
							<article id="resume">
								<h2 class="major">Marco's Resume</h2>
								<iframe src="https://drive.google.com/file/d/1OZC4fadC9w2PW38KaAmdHf8soU9Y9i1T/preview" width="100%" height="785" allow="autoplay"></iframe>
								If the embedding is broken, <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/MCConatiResume-1.pdf'>here</a> is a link to it!
							</article>

							<article id="TsaiDL">
								<h2 class="major">Numpy Neural Net</h2>
								<span class="image main"><img src="images/numpy.png" loading='lazy' alt="" /></span>
								<p>Full disclosure, this "project" is the result of homework in prof Tsai's deep learning for engineers course. For the first 4 weeks of the course, we slowly built the components of a neural net in numpy. This assignment involved putting those pieces(weight initialization, activation functions, loss function, forward/back prop, and gradient descent) together into one notebook. The neural net was then used as an autoencoder for representing 8 digits in a 3d space. My code is <a href = 'https://github.com/mconati/E208andE205/tree/main/dlStems/hw4'>here </a>. Also, the larger <a href = 'https://github.com/mconati/E208andE205/tree/main/dlStems'>dlStems </a> folder has other neat assignments from prof Tsai's course if you found this interesting!</p>
							</article>
							<article id="Torch">
								<h2 class="major">Learning Pytorch</h2>
								<span class="image main"><img src="images/torch.png" loading='lazy' alt="" /></span>
								<p>During the pandemic, I wanted to learn more about how neural nets are built in practice. In researching this, I found the Pytorch libraries. While studying Pytorch, I made <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/torch.pdf'>this</a> document. While my document generally follows the official Pytorch tutorials, it is very informal and more in line with my thought process while learning. This manifests as much less organization and frequent detours to fill in gaps (like why are GPUs good for Deep Learning):</p>
							</article>
							<article id="Alphazero">
								<h2 class="major">Recreating AlphaZero</h2>
								<span class="image main"><img src="images/chessbot.png" loading='lazy' alt="" /></span>
								<p>As a learning experience during the pandemic, I undertook a project with Natalia Orbach-Mandel and Ari Conati(my brother), to implement the <a href ='https://arxiv.org/abs/1712.01815'> AlphaZero</a> paper. This paper had revolutionized AI chess and Go bots in 2017, convincingly beating the world champion in each game. Our main goals were to learn about Pytorch, gain practical Reinforcement Learning experience, and have fun. Here is the <a href = 'https://github.com/AConati/amnom-chess'>code!</a> I am proud of this work because of the context; it represents us using the lockdown to better ourselves.</p>
							</article>
							<article id="DS">
								<h2 class="major">Self-studying RL</h2>
								<span class="image main"><img src="images/RL.png" loading='lazy' alt="" /></span>
								<p>In preparing to recreate AlphaZero, I completed David Silver's(one of the AlphaZero researchers) RL course on YouTube. While completing this course, I took pretty extensive notes, which I am transferring to digital form <a href = './notes/dl/RL.html'>here.</a></p>
							</article>
							<article id="ROAHM">
								<h2 class="major">ROAHMLab research (current)</h2>
								<span class="image main"><img src="images/roahm.png" loading='lazy' alt="" /></span>
								<p>I am working with Professor Vasudevan's ROAHM lab, with the goal of enhancing the dynamic behavior of his robotic manipulators. The code I am building is based off of <a href ='https://github.com/roahmlab/armour-dev'> armour-dev</a>. Armour-dev provide provably safe, real time manipulator motion (I recommend reading the paper to see how its guarenteed!). However, this motion tends to be conservative, with joint velocities leveling off well below their limits. I am designing and running experiments to identify/correct this behavior. Some
									examples of limiting factors could be overly strict constraints
									in the trajectory planner, introducing soft velocity constraints in the optimization problem, and reformatting the high level planner to pick more aggressive waypoints.</p>
							</article>
							<article id="ARMLAB">
								<h2 class="major">ARMLAB</h2>
								<span class="image main"><img src="images/armlab.png" loading='lazy' alt="" /></span>
								<p>This project was completed in a group during my first half-semester at UMich. We programmed a 5-DOF arm to recognize and localize blocks, path plan, and complete pick and place/stacking tasks. I wrote all of our forward and inverse kinematics code for this project, and worked in a pair to develop our simple motion planner. Our code for this project is available <a href ='https://github.com/mconati/ARMlab/tree/main/armlab-f23-main'> here</a>.</p>
							</article>
							<article id="BOTLAB">
								<h2 class="major">BOTLAB (current)</h2>
								<span class="image main"><img src="images/mbot.png" loading='lazy' alt="" /></span>
								<p>In a group, I am building a mini forklift using the UMich MBot platform. MBot is unique as it can be built from relatively inexpensive parts (Jetson Nano, Raspberry pi, RPLidar, DC motors) and is open source. We will enhance the platform with a low level position controller, SLAM system, computer vision system for identifying mini crates, and 3D-printed gripper for grasping and moving said crates.</p>
							</article>
							<article id="BRG">
								<h3 class="major">Barton Research Group (current)</h3>
								<span class="image main"><img src="images/BRG.jpg" loading='lazy' alt="" /></span>
								<p>Working for professors Dawn Tilbury and Kira Barton, I am developing software and a controller for a  3D additive manufacturing printer specializing in conductive materials. The printer uses air pressure to extrude a silver based ink, and an A3200 motion controller to move the substrate. I am developing a process model to relate printing parameters, such as air pressure and stage speed, to the width and resistivity of the resulting line. Then, the controller will incorporate visual feedback to ensure proper printing.</p>
							</article>
							<article id="BlimpKF">
								<h2 class="major">EKF Blimp tracking</h2>
								<span class="image main"><img src="images/blimp.png" loading='lazy' alt="" /></span>
								<p>This project involved tracking a blimp using recorded(but very noisy) compass, GPS position, and thrust input data. The underlying, smooth path was determined using an EKF:</p>
									<span class="image main"><img src="images/blimpPath.png" loading='lazy' alt="" /></span>
								<p>The EKF uses vehicle dynamics to predict the position, and updates are made with the measurement value(although the measurement noise is considered in the correction step). Here is the <a href = 'https://github.com/mconati/E208andE205/blob/main/MConati_Blimp_EKF.ipynb'>code</a>, with thorough comments!</p>
							</article>
							<article id="e80">
								<h2 class="major">PID-based Aquatic Robot</h2>
								<span class="image main"><img src="images/e80.png" loading='lazy' alt="" /></span>
								<p>Sorry for the grainy picture, this project is from 2018 and at the time of making this site I have lost a lot of the materials. For this project, I worked in a team to build an Aquatic robot with homemade sensors. The robot was meant to navigate around Dana Point and collect water clarity, turbidity, and wind speed. <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/AquaticAV.pdf'>Here</a> is our report detailing the homemade sensors:</p>
								Embedded report:
								<iframe src="https://drive.google.com/file/d/10OWC-NB_38GZv3NSdP4KPEyNksLn1LR6/preview" loading='lazy' width="100%" height="600" allow="autoplay"></iframe>
								<p>I was primarily responsible for the navigation. Unfortunately, I lost the code at some point, but our robot was generally able to navigate well. The PID was purely GPS based(and our GPS had 3 m uncertainty), so the robot movement was pretty crude. Here is an example of it heading to a waypoint and back:</p>
								<span class="image main"><img src="images/e80Path.png" loading='lazy' alt="" /></span>
							</article>
							<article id="Drone">
								<h2 class="major">Particle filter localization</h2>
								<span class="image main"><img src="images/PF.png" loading='lazy' alt="" /></span>
								<p> This project involved localizing a simple robot using its onboard LIDAR and IMU. The prediction step was conducted using the robot's IMU data and system dynamics, while the LIDAR was used for localization corrections. Our predicted path closely mirrored the actual, "desired" path, and outperformed pure GPS localization. I worked on this project in a group(with Evan Hassman and Bowen Jiang) for the State Estimation course(E205) at Harvey Mudd. E205 was unique in that there were only four labs during the semester, so each of them was quite intensive(and that's why I justified including this as a project). Here is our <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/PFLocalization.pdf'>report</a> and <a href = 'https://github.com/mconati/E208andE205/blob/main/Lab4.ipynb'>code</a>!</a></p>
								Embedded report:
								<iframe src="https://drive.google.com/file/d/1vTsnt1TdV92INgLW-AfM3KXk-prkpNHl/preview" width="100%" height="600" allow="autoplay"></iframe>
							</article>
							<article id="Syntiant">
								<h2 class="major">Door Security-Syntiant</h2>
								<span class="image main"><img src="images/Syntiant.png" loading='lazy' alt="" /></span>
								<p>This was my senior capstone project, where I served as Team
									Lead for a group of five students in collaboration with Syntiant Corporation. We developed an
									entrance security system composed of a battery-powered tag that can be deployed on doors in
									secured areas to track their position in addition to software to identify anomalous activity.
									During this capstone, I wrote the event and state estimation code, while the rest of my team
									collected training data and designed a custom PCB for deployment. My code was comprised of
									two main components: a Kalman Filter for estimating the angle of a swinging door and a
									Convolutional Neural Net (CNN) for identifying anomalous events. The Kalman Filter was built
									in C++ and processed 9-axis Inertial Measurement Unit (IMU) data in real time to localize the
									sensor. I used the IMU's gyroscope to predict changes in angle and magnetometer for error
									corrections. My event detection system passed frames of 1-D sensor data to Syntiant's NDP120
									deep learning processor, where an onboard CNN identified key door events like knocking and
									opening. We were able to successfully deliver a prototype to Syntiant for further development
									into a marketable product. Unfortunately, as this project was completed for a company, the code is closed due to an NDA. But, <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/Syntiant.pdf'>this(pdf)</a> poster about our project was signed off on for public viewing:</p>
									Embedded poster:
									<iframe src="https://drive.google.com/file/d/18bU1Bz8OM1ERzhGqKCWNl3hRMsxHPNqs/preview" loading='lazy' width="100%" height="600" allow="autoplay"></iframe>
							</article>
							<article id="Millennium">
								<h2 class="major">Spatial Navigation-Millennium</h2>
								<span class="image main"><img src="images/space.png" loading='lazy' alt="" /></span>
								<p>This was my junior clinic project, where I worked in conjunction with four other Harvey Mudd students and liaisons from Millennium Space Systems.
									 We were tasked with augmenting a star tracker system to localize a Low Earth Orbit satellite in the event of a GPS lockout. We developed two means to do this. The first 
									 used the Earth's horizon as a reference, which could then localize the satellite in conjunction with the star tracker's attitude quaternion. Our second 
									 method determined position by observing the refraction of stars behind the earth's horizon. As this project was completed in collaboration with Millennium, the code is closed due to an NDA.
								</p>
							</article>
							<article id="AnalogDigitalFilter">
								<h2 class="major">Analog and Digital Filters</h2>
								<span class="image main"><img src="images/sallen.png" loading='lazy' alt="" /></span>
								<p>As a final project in my junior year, I worked with a lab partner to design and implement two
									low-pass filters for isolating a 10 Hz sine wave from a 10 Hz pulse train. This requires a low-pass filter to remove all of the high frequency noise. One of the filters was
									an analog 4 th order Butterworth filter, implemented directly on a breadboard using the Sallen-Key
									circuit. The other filter was implemented digitally as a 10 th order comb filter. Both filters
									successfully isolated the 10 Hz sine wave. Here is our <a href='https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/DigitalAnalog.pdf'> report(pdf)</a>. It has our Arduino and Matlab code at the end.</p>
									Embedded report:
									<iframe src="https://drive.google.com/file/d/1hWWA4k_bWVdaBxr6h0YpenTRBnLEgrG0/preview" width="100%" height="600" allow="autoplay"></iframe>	
							</article>
							<article id="MusicTrack">
								<h2 class="major">Musical Performance Tracking</h2>
								<span class="image main"><img src="images/perform.png" loading='lazy' alt="" /></span>
								<p>In conjunction with Brandon Apodaca, I created the backbone of a music tracking application. This system could ideally be adapted to create an application for following a performance and advancing the sheet music accordingly.</p>
								<p>Our system utilized Dynamic Time Warping to align query audio to the reference music score in realtime. Our system was reliably able to converge for monophonic audio performances. Here is our <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/MusicTrack.pdf'>paper</a> and our <a href = 'https://github.com/mconati/MusicStemsFinalProject'>code!</a></p>
								Embedded report:
								<iframe src="https://drive.google.com/file/d/1_Et7j9NNSfIcnr4PC48ipJXyulj3lgi5/preview" loading='lazy' width="100%" height="600" allow="autoplay"></iframe>
							</article>
							<article id="A">
								<h2 class="major">A* search City Design</h2>
								<span class="image main"><img src="images/radio.png" loading='lazy' alt="" /></span>
								<p>I completed this project as a fun way to familiarize myself with A* search (and graph traversals in general). The motivation is that a city planner wants to add trails, gravel roads, and paved roads between n settlements, such that the longest travel time in the network doesn't exceed d days. In this scenario, no trail&lttrail&ltgravel&ltpaved for travel speed, but cost also increases as connection quality increases. So, this program wants to avoid making the more expensive connections if necessary.
								This program is a tool that takes in n, d as parameters and plots a possible network that meets the requirements. Since this was just a learning experience, the program is not very smart. It works with the following pseudocode:</p>
								
								Given settlement locations [x,y], an equation f(distance, trail type) that gives travel time in days for a certain distance and trail type, and a maximum travel time d days.
								<p></p>Loop:
								<ol>
								<li>Use A* to find the longest path in the current network in days</li>
								<li>If it is longer than d days, upgrade the longest path (nothing&lttrail&ltgravel&ltpaved)</li>
								<li>Else if longest path is less than d days, return the network!</li>
							</ol>
								<p></p>
								<a href = 'https://github.com/mconati/MiscCode/blob/main/network.py'>The code</a> isn't the smartest since it will start making trails that might not end up getting used once better roads are built. But, it does do a good job avoiding roads until they are necessary, which could be valuable assuming roads are more costly. An easy improvement would be to make one final pass and remove unnecessary connections at the end. Here is an example of a generated network where n=15 settlements and d=15 days:
								<span class="image main"><img src="images/Example.PNG" loading='lazy' alt="" /></span>
								It does exhibit some good behaviors like saving roads for long connections. But, it is certainly not ideal.
							
							</article>

							<article id="e190">
								<h2 class="major">Shazam Paper</h2>
								<span class="image main"><img src="images/STFT.png" loading='lazy' alt="" /></span>
								<p>I implemented the Shazam music recognition algorithm in numpy as a project for prof Tsai's DSP course. My system was able to reliably create a database of songs and then match noisy clips of those songs to the originals. The general algorithm is:</p>
								For creating a database:
								<ol>
								<li>Take the Short-Time-Fourier-Transform of a song. The STFT contains information about which frequencies are present at different points in time. The cover art for this project is an STFT</li>
								<li>Identify peaks in the STFT that have the highest magnitude. These points represent the "loudest" notes in the music and are thus most likely to represent the desired signal instead of background noise.</li>
								<li>Pair peaks into hashes. A pair of peaks is defined by the frequency of peaks and the time between them. Hashes are more likely to be unique to a song(many songs will have the same notes, but pairs of notes are more unique)</li>
								<li>Store a collection of hashes for each song. The greater the amount of hashes, the more space is necessary, but accuracy also increases</li>
								</ol>
								<p></p>
								
								For identifying a song:
								<ol>
								<li>Use the same process from creating the database to find hashes for the query</li>
								<li>For each song in the database
								<ol>
								<li>Find all matching hashes between query and database song. Calculate the time difference = (time of hash in query)-(time of hash in database song) for each hash</li>
								<li>Group the hash time differences into a histogram</li>
								<li>The highest value in the histogram is the score for that database song. The intuition here is that the matching song will have many hashes with the same time offset (time offset caused by the clip not necessarily starting at the beginning of the song)</li>
								</ol>
								</li>
								<li>Return the highest scoring database song</li>
							
							</ol>

							</article>
							<article id="CNN">
								<h2 class="major">CNNs and Autoencoders</h2>
								<span class="image main"><img src="images/CNN.png" loading='lazy' alt="" /></span>
								<p>To get practical experience with autoencoders, I solved the MNIST handwritten digit classification problem in two ways:</p>
								<ol>
									<li>Direct classification of handwritten digit images with a Convolutional Neural Net(CNN)</li>
									<li>Training an autoencoder on digit images, and using it as the backbone for a CNN</li>
								</ol>
								<p></p>
								I used a small dataset to make training more difficult. As a result, transfer learning from the autoencoder created a much smoother and quicker training curve. <a href="https://github.com/mconati/MiscCode/blob/main/CNNsAndRNNs/CNNTransferLearning.ipynb">Here</a> is my notebook!
							</article>
							<article id="LSTM">
								<h2 class="major">LSTM Numerical Translation</h2>
								<span class="image main"><img src="images/LSTM.png" loading='lazy' alt="" /></span>
								<p>As my first introduction to LSTMs and Sequence to Sequence models, I took on a numerical/word translation problem. Given a numerical symbol(I.E "8"), my LSTM would translate it to the word representation(I.E "eight"). My <a href = 'https://github.com/mconati/MiscCode/blob/main/CNNsAndRNNs/LSTMNumericalToWord.ipynb'>notebook</a> is split into three parts: </p>
								<ol>
									<li>Data Preparation and Research: First, I had to create the numerical/word dataset. I also had to research the sequence to sequency problem so that I could implement it in Pytorch.</li>
									<li>Implement and Train the model: I trained the model using my dataset, plotting my loss as training progressed. I also experimeted with different model hyperparameters.</li>
									<li>Analysis: I tried to identify what failure modes the model experienced.</li>
								</ol>
								<p></p>
								My notebook is thoroughly commented, have fun checking it out!
							</article>
							<article id="RNN">
								<h2 class="major">RNN Sentence Classification</h2>
								<span class="image main"><img src="images/RNN.png" loading='lazy' alt="" /></span>
								<p>For my first project with Recurrent Neural Networks(RNNs), I created an RNN model to classify sequences of characters(sentences, words, letters) as Spanish or English. My <a href="https://github.com/mconati/MiscCode/blob/main/CNNsAndRNNs/RNNClassification.ipynb">notebook</a> does the following:</p>
								<ol>
									<li>Create a dataset: I started with the Spanish Billion Word Corpus and torchtext English Wikipedia text files. I created a Dataset of 100 character long chunks in each language.</li>
									<li>Train the model: My RNN had a simple classifier, which used the RNN cell state at the end of a sequence to predict whether the sequence was Spanish or English </li>
									<li>Experimentation: I experimented with various RNN hidden sizes and RNN layer numbers</li>
									<li>Analysis: I tried to get intuition for what letters/phrased led to the RNN decision</li>
								</ol>
							</article>
							<article id="Pendulum">
								<h2 class="major">Inverted Pendulum Simulation</h2>
								<span class="image main"><img src="images/IP.png" loading='lazy' alt="" /></span>
								<p>As the final project in Harvey Mudd's advanced signals and systems course, I designed and simulated an inverted pendulum on a cart subject to distrubances. Attached and embedded is my project <a href = 'https://github.com/mconati/WebsitePDFs/blob/main/Website%20PDFs/Inverted_Pend.pdf'>report!</a> My simulink diagrams and matlab code are at the end of my report.</p>
								<iframe src="https://drive.google.com/file/d/1UJbaCOkoYJurHPpTJ-Pk0XWEhm1KBXvm/preview" loading='lazy' width="100%" height="600" allow="autoplay"></iframe>
							</article>
							<article id="searches">
								<h2 class="major">Testing array searches</h2>
								<span class="image main"><img src="images/search.png" loading='lazy' alt="" /></span>
								<p>When I was learning about array-searching algorithms, I wanted to cement my understanding of them. To this end, I implemented bubble, selection, quick, and merge sort. Each program makes a randomized array of size 10000, and then measures the sorting process runtime, printing it out. The <a href = 'https://github.com/mconati/MiscCode/tree/main/Sorts'>code</a> is not too well commented since this was done as a learning experience.</p>
							</article>
							<article id="rats">
								<h2 class="major">Solving a riddle</h2>
								<span class="image main"><img src="images/rats.png" loading='lazy' alt="" /></span>
								<p>A fellow Mudder gave me the following riddle:
									<p></p><i>Imagine you are a scientist with 2 rats, 9 bottles, and one hour. One bottle contains poison which will kill a rat in exactly 30 minutes if consumed. How can you feed the rats from the bottles to determine the poison? What if you had r rats and n minutes?</i>
								</p>
								<p>I thought this was pretty fun to solve, so I made a dynamic-programming solution for the r rat, n minute case <a href = 'https://github.com/mconati/MiscCode/blob/main/rats.py'>here!</a></p>
							</article>
							<article id="hashTree">
								<h2 class="major">Datastructures</h2>
								<span class="image main"><img src="images/binary.png" loading='lazy' alt="" /></span>
								<p>For Harvey Mudd's Datastructures course, we completed a variety of courses to build comfort with C++ and familiarity with common datastructures. This project highlights a few of my favorites. Each element in the list links to my code for the course:</p>
								<ol>
									<li><a href = 'https://github.com/mconati/DataStructures/tree/main/LinkedList'>Linked List implementation</a></li>
									<li><a href = 'https://github.com/mconati/DataStructures/tree/main/BinaryTreeSpellCheck'>A spellchecker built from a randomized tree!</a></li>
									<li><a href = 'https://github.com/mconati/DataStructures/tree/main/ChunkyString'>ChunkyString. This is a modified string where strings are split into linked chunks(IE arrays) of n characters. This makes insert and erase time defined (as opposed to not clearly defined for standard strings)</a></li>
									<li><a href = 'https://github.com/mconati/DataStructures/tree/main/HashSpellCheck'>Hash Table spellchecker</a></li>
								</ol>
							</article>

						
						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact</h2>
								<form method="post" action="https://formspree.io/f/xgeqpgzr">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" placeholder="Your Name" required/>
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" placeholder="Your Email" required/>
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="4"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Reset" /></li>
									</ul>
								</form>
								<ul class="icons">
									<li><a href="https://www.linkedin.com/in/marco-conati-ab71ab149" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
								</ul>
							</article>

						<!-- Elements -->
							<article id="elements">
								<h2 class="major">Elements</h2>

								<section>
									<h3 class="major">Text</h3>
									<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
									This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
									This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
									<hr />
									<h2>Heading Level 2</h2>
									<h3>Heading Level 3</h3>
									<h4>Heading Level 4</h4>
									<h5>Heading Level 5</h5>
									<h6>Heading Level 6</h6>
									<hr />
									<h4>Blockquote</h4>
									<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
									<h4>Preformatted</h4>
									<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
								</section>

								<section>
									<h3 class="major">Lists</h3>

									<h4>Unordered</h4>
									<ul>
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Alternate</h4>
									<ul class="alt">
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Ordered</h4>
									<ol>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis viverra.</li>
										<li>Felis enim feugiat.</li>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis lorem.</li>
										<li>Felis enim et feugiat.</li>
									</ol>
									<h4>Icons</h4>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
									</ul>

									<h4>Actions</h4>
									<ul class="actions">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Table</h3>
									<h4>Default</h4>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>

									<h4>Alternate</h4>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>
								</section>

								<section>
									<h3 class="major">Buttons</h3>
									<ul class="actions">
										<li><a href="#" class="button primary">Primary</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button">Default</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
										<li><a href="#" class="button icon solid fa-download">Icon</a></li>
									</ul>
									<ul class="actions">
										<li><span class="button primary disabled">Disabled</span></li>
										<li><span class="button disabled">Disabled</span></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Form</h3>
									<form method="post" action="#">
										<div class="fields">
											<div class="field half">
												<label for="demo-name">Name</label>
												<input type="text" name="demo-name" id="demo-name" value="" placeholder="Jane Doe" />
											</div>
											<div class="field half">
												<label for="demo-email">Email</label>
												<input type="email" name="demo-email" id="demo-email" value="" placeholder="jane@untitled.tld" />
											</div>
											<div class="field">
												<label for="demo-category">Category</label>
												<select name="demo-category" id="demo-category">
													<option value="">-</option>
													<option value="1">Manufacturing</option>
													<option value="1">Shipping</option>
													<option value="1">Administration</option>
													<option value="1">Human Resources</option>
												</select>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-low" name="demo-priority" checked>
												<label for="demo-priority-low">Low</label>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-high" name="demo-priority">
												<label for="demo-priority-high">High</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-copy" name="demo-copy">
												<label for="demo-copy">Email me a copy</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-human" name="demo-human" checked>
												<label for="demo-human">Not a robot</label>
											</div>
											<div class="field">
												<label for="demo-message">Message</label>
												<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
											</div>
										</div>
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</form>
								</section>

							</article>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Marco Conati. Design: <a href="https://html5up.net/license">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
